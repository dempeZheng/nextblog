---
layout: post
title:  " mysq千万级分页优化"
date:  2018-05-27 12:39:04
type: mysql
categories: [mysql]
keywords: mysql,分页,优化,千万级
---
## 写在前面

最近碰到一个分页查询消费记录问题，某个大主播消费记录百万级别的，翻页都后面越来越慢

业务反馈问题sql：

```
SELECT * FROM `t_consume_log` FORCE INDEX(idx_consume) WHERE userid = 301465268 and appid in(0,1,4,5,6,16) ORDER BY addtime desc LIMIT 100000, 12 
```

explain了一下sql，已经索引已经走了是预期的了。

```
+----+-------------+------------------------+-------+------------------------+------------------------+---------+------+--------+-----------------------------+
| id | select_type | table                  | type  | possible_keys          | key                    | key_len | ref  | rows   | Extra                       |
+----+-------------+------------------------+-------+------------------------+------------------------+---------+------+--------+-----------------------------+
|  1 | SIMPLE      | t_consume_log | range | idx_consume | idx_consume | 6       | NULL | 247357 | Using where; Using filesort |
+----+-------------+------------------------+-------+------------------------+------------------------+---------+------+--------+-----------------------------+
```

直接在备库执行了下sql，整整花费了一分钟。`12 rows in set (1 min 56.10 sec)`

mysql没有想象的那么只能， `LIMIT 100000, 12` ，mysql会读取100000+12行，然后过滤最后12行！！！
也就是说分页查询，越到后面越慢。

## 解决方案
这个是个比较常规的问题，搜索了一下，很多解决方案。大概可以分为三种。

### 1)业务限制

通过业务限制，超过100页的数据不让查询。简单粗暴，但是并不是所有的产品经理都能接受。

### 2)查询带上上一页最后的id
以上面的场景为例，这里可以带上addtime，

```
SELECT * FROM `t_consume_log` FORCE INDEX(idx_consume) WHERE userid = 301465268 and appid in(0,1,4,5,6,16) and addtime>1524998982 ORDER BY addtime desc LIMIT  12 
```

explain了一下，扫描的行数减少了很多。性能至少提升了1000倍以上。查询一下，需要`12 rows in set (0.03 sec)`
但是问题在于是不是一定能拿到上一页的最大的addtime，如果能，那是个不错的选择。

```
+----+-------------+------------------------+-------+-----------------------------------+------------------------+---------+------+-------+------------------------------------------+
| id | select_type | table                  | type  | possible_keys                     | key                    | key_len | ref  | rows  | Extra                                    |
+----+-------------+------------------------+-------+-----------------------------------+------------------------+---------+------+-------+------------------------------------------+
|  1 | SIMPLE      | t_consume_log | range | ix_addTime,idx_consume | idx_consume | 10      | NULL | 26252 | Using where; Using index; Using filesort |
+----+-------------+------------------------+-------+-----------------------------------+------------------------+---------+------+-------+------------------------------------------+
```

### 3)延时关联，利用覆盖索引
 
```
 SELECT * FROM `t_consume_log` FORCE INDEX(idx_consume) WHERE userid = 301465268 and appid in(0,1,4,5,6,16) ORDER BY addtime desc LIMIT 100000, 12 
```

 这条sql慢的原因是因为要查询很多附属的字段，
 假设我们只需要查询有索引的字段，比如consumeid，appi，addtime，userid，那么查询速度是很快的，
 执行了一下，只要`12 rows in set (0.08 sec)`

 所以，我们不妨把sql优化一下，改成

```
SELECT * FROM t_consume_log a JOIN (SELECT consumeid  FROM `t_consume_log`  WHERE userid = 301465268 and appid in(0,1,4,5,6,16) ORDER BY addtime desc LIMIT 72888, 12) b ON a.consumeid = b.consumeid;
```

测试了一下，性能也提升将近1000倍，`12 rows in set (0.08 sec)`


## 总结

解决方式，优先考虑1，在考虑2，再考虑3.



