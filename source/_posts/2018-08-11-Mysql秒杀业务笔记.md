---
layout: post
title:  "Mysql秒杀业务笔记"
date:  2018-08-11 22:39:04
type: mysql
categories: [mysql]
keywords: mysql,InnoDB,行锁,秒杀
---
## 场景
需要保证用户账户余额更新，同时记录账户变更日志，变更日志有coinBefore，coin，保证日志coinBefore准确。
获取coinBefore必须通过`select coin from user where userId=${userid}`,
逻辑如下：

```
1.查询余额记录内存coin
2.begin
2.1更新余额（coin=coin-${coin}）
2.2 记录账户变更日志（coinBefore=coin（1步骤中查询的coin））
3.commit
```
【注】数据库为Mysql(InnoDB)
上面逻辑可以保证coin准确，因为跟新余额的时候innoDB有行锁。但是账户变更日志的coinBefore就没办法保证一致了。

## 解决方案
解决这个问题首先想到的就是加锁，加锁的方式主要有两种：  
1）依赖外部的分布式锁  
2）依赖db锁  

### 方案一 依赖分布式锁
将上述逻辑通过分布式锁包装成原子的，就可以解决coinBefore的准确性的问题了。
优点：分担了数据库的压力，业务侧比较容易控制
缺点：代码变复杂，

### 方案二 依赖DB锁
#### 方案2.1 依赖Mysql InnoDB的`select coin  ... for update`的排他锁

```sql
1.begin
1.1 select coin from t_user where user=${userId} for update
1.2 update user set coin=coin-${coin} where user=${userId}
1.3 insert user_log(coinBefore,coin) into values(${coinBefore},${coin})
2.commit
```

#### 方案2.2  依赖Mysql InnoDB的update语句的行锁

```sql
1.begin
1.1 update user set coin=coin-${coin} where user=${userId}
1.2 select coin from t_user where user=${userId}
1.3 insert user_log(coinBefore,coin) into values(${coinBefore},${coin})
2.commit
```
1.1(方案2.2)更新余额的时候已经对当前行加锁，故1.2查询到的时候更新后的余额，且不会被修改（事务没提交，行锁还没释放）

方案2.1和方案2.2其实没有本质区别，都是依赖InnoDB的行锁。而Mysql在秒杀的场景下表现的并不算好。假设系统中有个别用户有极为频繁的余额变更的场景，那么Mysql可能会面临不小的压力。
![Alt text](./images/1533952178081.png)
单行同一个用户1024个并发的时候，tps已经只有30了，所以如果依赖Mysql的行锁来保证数据一致性，而且什么都不做的话，可能恶意用户花很少的代价，可能就让你的服务崩溃。
所以如果要依赖InnoDB的行锁，作为一个健壮的系统，是必须要去做一些优化或者限制的。

### InnoDB秒杀业务的优化
- 限制并发连接 
 
我们可以看到Mysql在并发连接较少的时候性能还是能接受的。（16个左右的并发，性能最高，大约有1.8tps）。

限制并发连接可以通过业务侧，服务端或者DB层来限制。
服务端比如限制连接池的数量，但是这个对于集群部署，限制不太可控。
另外从DB测限制连接池数量相对来说比较靠谱。但是早期的版本5.6之前，Mysql还没有对连接池的支持。

- 关闭死锁检测 

并发较高的时候，基本上有一半的cpu都被死锁检测线程给占用。从压测的图上面可以看出，关闭死锁检测对秒杀场景的性能提升还是非常明显的

- 修改源码 

这个门槛比较高，不是顶尖的团队，可操作性不强。
可以参考阿里针对秒杀场景对Mysql的优化（排队，group commit）

